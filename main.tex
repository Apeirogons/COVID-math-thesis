\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{mathrsfs}
\newcommand{\nR}{\mathscr{R}}
\newcommand{\nr}{r}
\overfullrule=0pt


\title{$\nR$(t) and r(t) Estimation}
\author{Matthew So}
\date{2021}

\begin{document}

\maketitle



\tableofcontents

\section{Rationale}
This project focuses on methods to estimate $\nR(t)$ and $r(t)$ from epidemiological incidence time-series data. $\nR(t)$ is the time-varying reproductive number, equal to the number of expected infections caused by any given infected individual. $r(t)$ is the speed of infection, equal to the daily proportion increase in incidence. There are several ideas related to $\nR(t)$ estimation in this project:

\begin{enumerate}
    \item Modelling. Specifically, real-world incidence data appears to have periodicity, which may be due to weekday effects in observations. The SEIR-based model discussed later specifically generates data with similar weekly spikes in observations.
    \item Smoothing. Real-world data is noisy, and smoothing can both reduce the noise level and remove the aforementioned periodic effects. 
    \item Comparison of $\nR(t)$ estimation methods, including "Shifts". It was hypothesized by Jonathan Dushoff that using the Wallinga-Teunis \cite{WallingaTeunis} cohort $\nR(t)$ estimation method on appropriately shifted symptomatic incidence data would allow for an approximate estimate of the case $\nR(t)$. A more standard method for case $\nR(t)$ measurement is the Cori $\nR(t)$ method.
    \item Comparison of shifting curves and deconvolution to reconstruct the \textit{incidence of infection} curve from the \textit{incidence of symptoms} or \textit{symptomatic incidence} curve. A suggestion by the Cobey Lab \cite{Gostic} indicates that, given an ideal world, deconvolution is the more appropriate option; however, is this feasible given a noisy and periodic world? 
\end{enumerate}

\section{To-do}
This project is not fully complete. A list of things which still have to be done can be found here.

\begin{enumerate}
	\item I write that some methods are not as effective as others... this appears to be the case visually, but perhaps numbers would be more effective (and certainly more scientific). 
\end{enumerate}


\section{Modelling}

\subsection{Rationale}
Real-world COVID-19 data has clear, "spiky" periodicity. It is hypothesized in this work that this "spikiness" primarily reflects daily changes in observations. Any trends in infection, such as changes in $\beta(t)$, would be heavily smoothed by the incubation period; however, this is inconsistent with the consistent single-day spikes found in real data. 

\clearpage
\begin{figure}
    \centering
    \includegraphics[scale=0.5]{figures/real_dataviz.png}
    \caption{Real-world data has spiky and periodic effects. Data taken from Our World in Data, Canada and US daily case data \cite{OWID}.}
    \label{fig:my_label}
\end{figure}

\clearpage
\begin{figure}
	\centering
    \includegraphics[scale=0.25]{figures/United States_weekday.png}
    \caption{Real-world data may show trends in incidence based on weekday. Each timeseries on this plot represents incidence for a different weekday. }
    \label{fig:my_label}
\end{figure}

For example, in the US, Mondays appear to have, on average, the lowest incidence of any weekday.

Therefore, in order to effectively evaluate any potential improvements to $\nR(t)$ estimation methods, it is important to develop a model with periodic dynamics similar to that found in the real-world. 

\subsection{About the model}
The current model is a discrete-time model based on the SEIR framework, which also models weekday trends in observation data. The main idea behind the model is that the probability density function for an infectee's observation time is modified such that observation on a Monday (for example) is more likely than the other days.

This model has three supported running modes, each related to how much noise is present in the model: fully deterministic, simple observation noise, and full dynamical noise. "Simple observation noise" determines the number of daily observations by sampling from some probability distribution, such that the expected value is lower than a parameter $detectionProb$. There also exists an unsupported "generalized observation noise" mode, which implements the observation noise found in the simple mode and adds dynamical noise to observation transitions.

For the purposes of this model, dynamical noise is defined by having to sample from a probability distribution to determine the time of a transition event; for example, sampling from an exponential distribution to determine a time for a $E \rightarrow I$ transition. ("Dynamical noise" is a synonym for "process noise", and is used for greater clarity in this text). Observation noise is defined by having to sample from a probability distribution to determine the number of individuals observed on a given day, given that the number of individuals who "could have" been observed on this day has already been previously decided.

\subsection{Explanations for features in the model}

\subsubsection{Conventions}
The sum of two probability distributions $X$ and $Y$ is denoted as $X+Y$, and is computed as the convolution of their probability density functions. The expected value is denoted as $E[X]$. Temporary variables have self-explanatory names. Also, variables in $camelCase$ are equivalent to variables named $like\_this$. 


\subsubsection{State variable explanations}
All state variables are initialized to 0 except $S \gets 10,000,000$. 

\begin{itemize}
    \item $S$: susceptible.
    \item $E$: exposed, but non-infectious
    \item $I$: infectious
    \item $R$: recovered (or dead)
    \item $O$: cumulative infectious individuals who have been observed 
    \item $t$: time since epidemic start.
\end{itemize}

\subsubsection{Parameter/Function explanations}
\begin{itemize}
    \item $\beta(t)$: Same meaning as in typical SEIR models.
    \item $\nR_0$: Implicitly used to define $\beta(t)$. Set to 2.1 with $t < 150$, 0.99 with $t<200$, 0.9 with $t<300$, else 1.2.
    \item $baseObservationDist$: Probability density function of time for an infection to be observed. This PDF is modified based on the day of the week. Currently set to discrete lognormal distribution with $\mu$=1.7, log-SD=0.5 
    \item $incubationDist$: Probability density function of time to go from $E \rightarrow I$. Currently set to discrete lognormal distribution with $\mu$=1.63, log-SD=0.5. \cite{McAloon}
    \item $infectiousDist$: Probability density function of time to go from $I \rightarrow R$. (time spent infectious). Currently set to exponential distribution with mean=10 days. 
    \item $\kappa$: 1/(dispersion parameter) in an alternatively parameterized negative binomial distribution. \cite{NegBinom} $negBinom(mean, 0)$ is implemented as the Poisson. I chose 0 as the value of $\kappa$, implicitly making all instances of $negBinom$ actually $Poisson$.
    \item $negBinom$: Negative binomial distribution parameterized by (mean, $\kappa$). 
    \item $dayScalers$: On each weekday, the probability of observation is multiplied by this value. Set to 1.2 for Monday and Tuesday and 1 otherwise. 
    \item $observationProb$: The total probability that an infected individual will be observed. Set to 0.8.
    \item $t_{max}$: Maximal value of $t$ for simulation. Set to 401.
\end{itemize}

\subsubsection{Derived variable explanations}
\begin{itemize}
    \item $incidence$: The number of new individuals infected today that weren't infected yesterday. At t=0, incidence is set to 10.
    \item $expectedIncidence$: The expected number of individuals that would be infected today. This makes no adjustments for past dynamical noise, and effectively asks the question "what if dynamical noise ceased to exist today?" A timeseries of $expectedIncidence$ is considered to be optimally smoothed.
    \item $\mu$: The reciprocal of the $E[incubationDist]$, analogous to the $E \rightarrow I$ controlling parameter in SEIR model.
\end{itemize}

\subsection{Explanation of model logic}
\subsubsection{Pre-simulation setup}

\begin{enumerate}
    \item Precompute an observation distribution for every day in the week. For each weekday, modify a copy of baseObservationDist such that each weekday in the distribution is multiplied by the corresponding item in dayScalers. Then, renormalize this distribution to have a sum of 1.

    \item For each weekday observation distribution, compute the probability $p$ that $weekdayObservationDist \leq (infectiousDist+recoveryDist)$. Then, that weekday's $adjustedObservationProb \gets obervationProb/p$. 
    
    \item Set values for each state variable. Set $N \gets sum(S, E, I, R)$. Additionally, set $t \gets -1$ for setup purposes.

\end{enumerate}

\subsubsection{Simulation}
These steps are executed for each desired value of t between 0 and $t_{max}$.
\begin{enumerate}
    \item Compute $\nR_t \gets \beta_t/\mu \cdot S/N$. This refers to instantaneous $\nR_t$.
    
    \item Compute the weekday, $t \pmod 7$.
    
    \item If t=0, then initialize $incidence$ to some number. Else, if running in full dynamical noise mode, compute $incidence = negBinom(SI\beta(t)/N, \kappa)$ and $expectedIncidence = SI\beta(t)/N$. Else, compute $expectedIncidence = incidence = SI\beta(t)/N$.
    
    \item Transition event times are put into a separate list with each element at each index representing the number of events at (index) days from now. 
        \begin{enumerate}
            \item dynamical noise mode: For each incident case today, choose an \linebreak $incubationTime (E \rightarrow I)$, $infectiousTime$, and $observationTime (E \rightarrow O)$ by sampling from $incubationDist$, $infectiousDist$, and the appropriate $weekdayObservationDist$ respectively. 
            
            \item Otherwise: Transition events are distributed amongst all future days with probability equal to their respective probability density functions. $E \rightarrow I$ events are proportional to $incubationDist$, $I \rightarrow R$ is proportional to $incubationDist + infectiousDist$, and $E \rightarrow I$ is proportional to the appropriate $weekdayObservationDist$ scaled by $obervationProb$. Note that the previous idea of enforcing \linebreak $observationTime \leq totalRecoveryTime$ is not accomplished here.

        \end{enumerate}

    \item Handle observation events.
        \begin{enumerate}
            \item dynamical noise mode/Generalized dynamical noise: For each incident case, $totalRecoveryTime$ is $incubationTime + infectiousTime$ days from now. If $observationTime \leq totalRecoveryTime$, then observe the incident case with probability of that weekday's \linebreak $adjustedObservationProb$. 
            \item Fully deterministic mode: The number of observations added is scaled by $observationProb.$
            \item Simple observation noise: The number of observations added at each point in the future is sampled from $negBinom(n_{obs}, \kappa)$.

        \end{enumerate}
    
    \item Execute all other transition events occurring today. For $S \rightarrow E, S=S-1, E=E+1$. For $E \rightarrow I, E=E-1, I=I+1$. For $I \rightarrow R, I = I-1, R = R+1$. For $E \rightarrow O, O = O+1$
    

    
    \item Store all state variables as well as $incidence$ and $expectedIncidence$ from today.
\end{enumerate}

\subsubsection{Post-simulation}
\begin{enumerate}
    \item Compute the generation interval, $infectiousDist + recoveryDist.$ 
    \item Compute case $\nR(t)$ by backward-convolving instantaneous $\nR(t)$ with the generation interval. This is implemented by using convolve(..., type='filter') in R.
    \item Compute $scaledIncidence$ and $scaledExpectedIncidence$ by multiplying $incidence$ and $expectedIncidence$ (respectively) by $observationProb$.
\end{enumerate}


\subsubsection{Previous simulation paradigm}
Before January 2020, this simulation model was an ordinary differential equation SEIR model, assuming that $E \rightarrow I$  resulted in a possible observation. The number of observed symptomatic cases each day was sampled from a beta-binomial distribution with a maximum size of the floor of the daily incident cases. However, this model did not support dynamical noise, nor did it support the weekly observation trends common in COVID-19 data. However, this model was effective for testing purposes.

\clearpage
\subsection{Simulation Images}

For the following simulations, $\nR_0(t)$ was defined according to the following function. This is, $\beta(t)$ was varied in such a way that $\frac{\beta(t)}{\mu(t)} = \nR_0(t)$. $\nR_0(t)$ is the target basic reproductive number for each $t$; that is, the reproductive number at this time if $\nR(t)$ was not scaled by $\frac{S}{N}$.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{figures/R0.png}
    \caption{$\nR_0(t)$}
    \label{fig:my_label}
\end{figure}

\subsubsection{Full dynamical noise}
As previously stated, runs with full dynamical noise implement noise for all model transitions. This results in highly variable true incidence values, as well as meaningful differences between runs.

This run is fairly typical for runs with dynamical noise, with incidence figures on the order of thousands. $\nR(t)$ does not tend to vary much between runs, as the pool of susceptible individuals remains high for all of these simulations.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/process_2_incidence.png}
    \caption{Incidence for a typical run containing full dynamical noise. Note that the expected incidence curve is shown instead of the true incidence curve due to high levels of noise in the true incidence curve.}
\end{figure}

\clearpage
\begin{figure}[h!]
\centering
\includegraphics[scale=0.5]{figures/process_2_prevalence.png}
\caption{Prevalence timeseries (E for exposed, I for infectious) for this run.}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[scale=0.5]{figures/process_2_Rt.png}
\caption{$\nR(t)$ for this run. Note that this instantaneous $\nR(t)$ does not differ significantly from the $\nR_0(t)$ curve.}
\end{figure}

However, it is possible for the infection to die out early, due to the first infectors recovering before infecting anyone. For the following run, the number of people initially infected was set to 1.

\begin{figure}[h!]
\centering
\includegraphics[scale=0.5]{figures/process_die1_incidence.png}
\caption{Incidence for a run where the infection dies out early.}
\end{figure}

\subsubsection{Simple observation noise}
The simple observation noise mode implements the following changes to the full dynamical noise mode:
\begin{enumerate}
	\item Noise is not introduced in determining the number of new infections.
	\item Noise is not introduced in determining the transitions from $E \rightarrow I$, or $I \rightarrow R$. 
\end{enumerate}


Runs using simple observation noise differ slightly, but not to the same extent as runs using full dynamical noise. This mode was implemented for two main reasons. Firstly, there was a need for the accurate comparison of different smoothing and deconvolution methods on $\nR(t)$ estimation. Under the dynamical noise mode, the simulation could randomly exhibit increased or decreased incidence than expected, causing the underlying $\nR(t)$ to not be equal to the $\nR(t)$ that could be estimated using the perfectly smoothed data. Secondly, there was a need for a suitable way to assess the quality of $r(t)$ estimation. $r(t)$ is defined by the logarithmic derivative of the true underlying incidence, so even the $expectedIncidence$ timeseries from the dynamical noise simulation mode resulted in a very noisy underlying $r(t)$. Note that the $expectedIncidence$ timeseries from the following plots are perfectly smooth due to not utilizing dynamical noise here. Runs using generalized observation noise appear similar, but this mode is unsupported and will not be discussed further.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/simple_observation_2_incidence.png}
    \caption{Incidence for a run using simple observation noise. Note that expected incidence in this case is equivalent to the true incidence.}
\end{figure}

\clearpage
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/simple_observation_2_prevalence.png}
    \caption{Exposed and infectious prevalence for the same run using simple observation noise.}
\end{figure}

\subsubsection{Fully deterministic}
The fully deterministic mode is equivalent to the simple observation noise mode, but also removes the noise when sampling $E \rightarrow O$ transitions. The underlying prevalence of the fully deterministic mode is equivalent to that of the simple observation noise mode. This mode was created to inspect the true shape of the symptomatic incidence curve unmodified by noise. 

\clearpage
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/Fully deterministic_incidence.png}
    \caption{Incidence for a fully deterministic run.}
\end{figure}


\section{Smoothing}

\subsection{Rationale}
Real-world data is noisy and periodic, and various smoothing methods were hypothesized to be effective at removing these effects. It was hoped that removing noise and periodic effects would improve the quality of $\nR(t)$ or $r(t)$ estimation.

\subsection{7-Day Smoothing}
While this is one of the simplest methods of smoothing, there was a strong theoretical rationale for the use of this method. The model explicitly modeled periodicity with a period of 7 days, so it was unsurprising that this method seemed to be the most effective at smoothing model data. This implementation uses a 7-day rolling (arithmetic) mean, and is centered after smoothing.

\clearpage
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/7day_smooth_ deterministic .png}
    \caption{Smoothing of deterministic simulation incidence.}
\end{figure}


\clearpage
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/7day_smooth_ process_1 .png}
    \caption{Smoothing of full dynamical noise simulation incidence.}
\end{figure}

\clearpage
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/7day_smooth_ simple_observation_1 .png}
    \caption{Smoothing of simple observation noise simulation incidence.}
\end{figure}

\subsection{Wavelet transform low-pass filter}
The discrete wavelet transform converts a timeseries into the wavelet domain, for which there are high-frequency and low-frequency wavelets. Wavelets are periodic functions localized in space, allowing for modelling of periodicity and spatial features that can change over time. All wavelets above a certain level (high-frequency wavelets) were set to zero in order to perform smoothing, although this seems like a crude approach. This works relatively well for certain wavelet parameters, such as using the db4 wavelet and removing all levels above 3. This has the benefit of being highly flexible, allowing for various levels of smoothing and different choices of wavelets. However, this method is not as effective as the 7-day smoothing.

\clearpage
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/wavelet_smooth deterministic .png}
    \caption{Smoothing of deterministic simulation incidence.}
\end{figure}


\clearpage
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/wavelet_smooth process_1 .png}
    \caption{Smoothing of full dynamical noise simulation incidence.}
\end{figure}

\clearpage
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/wavelet_smooth simple_observation_1 .png}
    \caption{Smoothing of simple observation noise simulation incidence.}
\end{figure}



\subsection{Fourier transform low-pass filter}
Similarly to the wavelet transform, the Fourier transform converts a timeseries to the frequency domain. One can set all frequencies above a threshold to zero to perform smoothing. However, this suffers the unique issue of not being very accurate at the beginning and end of the timeseries, and has therefore been largely ignored for the rest of the project.

\clearpage
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{figures/fft_smooth_ simple_observation_1 .png}
    \caption{FFT Smoothing of simple observation noise simulation incidence.}
\end{figure}

\section {$\nR(t)$ and $r(t)$ Estimation}
\subsection{Cori $\nR(t)$ Estimation}
The standard for estimating instantaneous $\nR(t)$ \cite{Cori}. This method works extremely well for non-noisy/periodic data, and is also robust to noisy/periodic data due to having an intrinsic 7-day smoothing window. This work linearly extrapolates several timesteps beyond  the original timeseries at the end of the timeseries, in order to improve the estimation stability at the end of the timeseries.

\clearpage
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{figures/estim_simple_observation_1.png}
    \caption{Cori estimation on data with simple observation noise. This was done using shifting of the incidence curves.}
\end{figure}


\subsection{Wallinga-Teunis $\nR(t)$ Estimation}
The standard for estimating case $\nR(t)$ \cite{WallingaTeunis}. This method also works very well for what it is intended to do, the estimation of case $\nR(t)$. This work linearly extrapolates several timesteps beyond  the original timeseries at the end of the timeseries, in order to improve the estimation stability at the end of the timeseries.

However, this method reacts to changes in $\nR(t)$ slower than the Cori method, and the original "Shifts" idea does not appear to be better than simply taking a Cori estimate and shifting it instead. This was implemented by using the EpiEstim WT estimation method on the observation data. This WT estimation was shifted forward by the mean time from infection to observation. As case $\nR(t)$  is backward-convolved from instantaneous $\nR(t)$ by the generation interval distribution, it may be possible to deconvolve the WT estimates in order to obtain "faster" estimates of case $\nR(t)$. However, this idea has not been thoroughly explored.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{figures/wt_comparison_deterministic.png}
    \caption{Comparison of WT Shifts and shifted Cori methods - deterministic simulation}
    \label{fig:my_label}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{figures/wt_comparison_process_1.png}
    \caption{Comparison of WT Shifts and shifted Cori methods - dynamical noise simulation}
    \label{fig:my_label}
\end{figure}

\clearpage
However, WT estimation performs well on its intended task.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{figures/wt_vs_true_deterministic.png}
    \caption{Comparison of WT method and true case $\nR(t)$ - deterministic simulation}
    \label{fig:my_label}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{figures/wt_vs_true_process_1.png}
    \caption{Comparison of WT method and true case $\nR(t)$ - dynamical noise simulation}
    \label{fig:my_label}
\end{figure}



\subsection{Naive $r(t)$ Estimation}
$r(t)$ can be defined as the logarithmic derivative of incidence \cite{Gostic}. As a discrete approximation to this, the first differences of the logarithm of incidence was used to calculate $r(t)$. For $r(t)$ estimation, symptomatic incidence data was first smoothed with a 7-day window, then the previous discrete approximation of the logarithmic derivative of incidence was calculated. 7-day smoothing was then applied once more to the naive $r(t)$ estimates, in order to get a more stable estimate. The estimates were then shifted backwards by the mean time from infection to observation. One issue with this double-smoothing method is that it does not return results for the 7 days at the beginning and 7 days at the end of the timeseries.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.4]{figures/rt_simple_observation_1.png}
    \caption{$r(t)$ estimation on data with simple observation noise. This was done using shifting of the incidence curves.}
\end{figure}


\section{Shifts vs. Deconvolution}

\subsection{Shifts}
Despite warnings by Gostic et al \cite{Gostic}. about the use of shifts instead of deconvolution in epidemic data, shifting timeseries appears to be superior when there exists noise in the data. Nonetheless, this section will continue to report on the timeseries deconvolution methods I had been working on.


\subsection{Richardson-Lucy Deconvolution}
Total variation-regularized Richardson-Lucy deconvolution is an iterative method following the equation below: \cite{RLLoss}
\begin{equation}
    o_{k+1} = \frac{i}{o_k * h} * (-h) \frac{o_k}{1-\alpha div(\frac{\nabla o_k}{|\nabla o_k|})}
\end{equation}

where $o$ represents the deconvolved image, $i$ represents the observed image, $h$ represents the point-spread function, $div$ is divergence, $\alpha$ is a regularization parameter, $int_z$ refers to integrating over all pixels of the image, and $*$ is the convolution operator.

While this equation looks complex, it can be derived from a simpler principle: the minimization of the following loss function. 
\begin{equation}
    J(o) = \underbrace{\int_z ((h*o)(x) - i(x) log(h*o)(x))dx}_{\mbox{Poisson log-likelihood}} + \underbrace{\alpha \int_z |\nabla o(x)| dx}_{\mbox{Total Variation regularization}}
\end{equation}


In the epidemiological context, $o$ represents the estimated incidence of infection, $i$ represents the symptomatic incidence, $h$ represents the incubation period distribution, $div$ reduces to the 1-dimensional derivative,  $\int_z$ refers to integrating over all times in the timeseries, and $\nabla$ also reduces to the 1-dimensional derivative.

With regularization, the Richardson-Lucy algorithm will converge to some reasonable value. However, in some cases, early stopping is still desirable. The Cobey Lab used a chi-squared statistic comparing the convolution of the deconvolved image to the observed image to perform early stopping. The total variation regularization was a modification of the Cobey Lab's R code.

\clearpage
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/deconv_deterministic.png}
    \caption{Regularized Richardson-Lucy deconvolution used on deterministic simulation, smoothed before deconvolution. Notice that this is more effective at reconstructing the peak compared to shifts without the presence of noise}
    \label{fig:my_label}
\end{figure}

\clearpage
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/deconv_process_1.png}
    \caption{Regularized Richardson-Lucy deconvolution used on simulation with dynamical noise, smoothed before deconvolution. Notice that this reconstruction is relatively poor.}
    \label{fig:my_label}
\end{figure}

\subsection{Optimizer-Based Deconvolutions}
Rather than using the Richardson-Lucy algorithm for deconvolution, one can also optimize the same underlying loss function using conventional optimizers. While this problem is too difficult for most of the SciPy optimizers, it is possible to use the Powell (or potentially other non-gradient optimizers) for this task. One upside of this idea is that it is relatively easy to implement deconvolutions based on new statistical models; for example, the negative binomial loglikelihood was used in place of the Poisson log-likelihood in one of my implementations. However, this method was not pursued further as it did not appear to outperform the regularized Richardson-Lucy implimentation.

\subsection{Wiener Deconvolution}
Wiener deconvolution performs deconvolution in the Fourier domain (deconvolutions are simple divisions in this domain), but adds an additional factor to the denominator. This suffers from similar problems compared to the previously discussed Fourier transform low-pass filters, and was not pursued further.

\section{Use of methods on real-world country data}
\subsection{Explanation}
The most promising methods (7-day smoothing, shifted Cori, and naive $\nr(t)$ estimation) were applied to some real-world data below.  Richardson-Lucy deconvolution (applied to 7-day smoothed data) was also applied to see its effectiveness on real-world data.

\begin{enumerate}
    \item Smoothing does not meaningfully matter for Cori $\nR(t)$ estimation, but is necessary for naive $\nr(t)$ estimation.
    \item 7-day smoothing works well. 
    \item Richardson-Lucy deconvolution can be applied to real-world COVID-19 data.
\end{enumerate}


\subsection{Figures - Germany}
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/smoothing_Germany.png}
    \caption{Use of 7-day smoothing on German real-world incidence data.}
    \label{fig:my_label}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.5]{figures/deconv_Germany.png}
    \caption{Deconvolution on German real-world incidence data.}
    \label{fig:my_label}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/estim_Germany.png}
    \caption{Use of shifted Cori $\nR(t)$ estimation methods on German real-world incidence data.}
    \label{fig:my_label}
\end{figure}

\clearpage
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/rt_Germany.png}
    \caption{Naive $\nr(t)$ estimation method used on German real-world incidence data.}
    \label{fig:my_label}
\end{figure}

\clearpage
\subsection{Figures - Italy}
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/smoothing_Italy.png}
    \caption{Use of 7-day smoothing on Italian real-world incidence data.}
    \label{fig:my_label}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.5]{figures/deconv_Italy.png}
    \caption{Deconvolution on Italian real-world incidence data.}
    \label{fig:my_label}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/estim_Italy.png}
    \caption{Use of shifted Cori $\nR(t)$ estimation methods on Italian real-world incidence data.}
    \label{fig:my_label}
\end{figure}

\clearpage
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/rt_Italy.png}
    \caption{Naive $\nr(t)$ estimation method used on Italian real-world incidence data.}
    \label{fig:my_label}
\end{figure}

\clearpage
\subsection{Figures - South Korea}
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/smoothing_South Korea.png}
    \caption{Use of 7-day smoothing on South Korean real-world incidence data.}
    \label{fig:my_label}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=0.5]{figures/deconv_South Korea.png}
    \caption{Deconvolution on South Korean real-world incidence data.}
    \label{fig:my_label}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/estim_South Korea.png}
    \caption{Use of shifted Cori $\nR(t)$ estimation methods on South Korean real-world incidence data.}
    \label{fig:my_label}
\end{figure}

\clearpage
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/rt_South Korea.png}
    \caption{Naive $\nr(t)$ estimation method used on South Korean real-world incidence data.}
    \label{fig:my_label}
\end{figure}

\section{Use of methods on real-world variant data}
The previously described $\nr(t)$ estimation methods were used on Ontario COVID-19 data curated by Michael Li \cite{mli}. 

\clearpage
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/N501Y.png}
    \caption{Estimated N501Y variant incidence (N501Y test positivity rate multiplied by total incidence)}
    \label{fig:my_label}
\end{figure}

\clearpage
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{figures/N501Y_r(t).png}
    \caption{Estimated N501Y variant r(t). Note that this seems too spiky without smoothing, but is not fully up to date with a smoothing window of 7. To deal with this issue, the smoothing window could be reduced, or we could use extrapolation methods, or we could attempt using a different smoothing method.}
    \label{fig:my_label}
\end{figure}



\begin{thebibliography}{2}

\bibitem{WallingaTeunis}
Wallinga, J. (2004). Different Epidemic Curves for Severe Acute Respiratory Syndrome Reveal Similar Impacts of Control Measures. American Journal Of Epidemiology, 160(6), 509-516. https://doi.org/10.1093/aje/kwh255

\bibitem{Cori}
Cori, A., Ferguson, N., Fraser, C., \& Cauchemez, S. (2013). A New Framework and Software to Estimate Time-Varying Reproduction Numbers During Epidemics. American Journal Of Epidemiology, 178(9), 1505-1512. https://doi.org/10.1093/aje/kwt133

\bibitem{Gostic}
Gostic, K., McGough, L., Baskerville, E., Abbott, S., Joshi, K., \& Tedijanto, C. et al. (2020). Practical considerations for measuring the effective reproductive number, Rt. PLOS Computational Biology, 16(12), e1008409. https://doi.org/10.1371/journal.pcbi.1008409


\bibitem{OWID}
Roser, M., Ritchie, H., Ortiz-Ospina, E., \& Hasell, J. (2020). Coronavirus Pandemic (COVID-19). OurWorldInData.org. Retrieved 24 February 2021, from https://ourworldindata.org/coronavirus.

\bibitem{McAloon}
McAloon, C., Collins, Á., Hunt, K., Barber, A., Byrne, A., \& Butler, F. et al. (2020). Incubation period of COVID-19: a rapid systematic review and meta-analysis of observational research. BMJ Open, 10(8), e039652. https://doi.org/10.1136/bmjopen-2020-039652


\bibitem{NegBinom}
R: The Negative Binomial Distribution. Stat.ethz.ch. (2021). Retrieved 24 February 2021, from https://stat.ethz.ch/R-manual/R-devel/library/stats/html/NegBinomial.html.

\bibitem{RLLoss}
Dey, N., Blanc-Féraud, L., Zimmer, C., Roux, P., Kam, Z., Olivo-Marin, J., \& Zerubia, J. (2004). 3D Microscopy Deconvolution using Richardson-Lucy Algorithm with Total Variation Regularization. INRIA. Retrieved from https://hal.inria.fr/inria-00070726/document

\bibitem{mli}
Li, M. (2021). COVID19-Canada. github.com. Retrieved 10 March 2021, from https://wzmli.github.io/COVID19-Canada/.
    


\end{thebibliography}
\end{document}
